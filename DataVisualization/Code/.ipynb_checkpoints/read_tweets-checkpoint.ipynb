{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk.classify\n",
    "import cPickle\n",
    "import re\n",
    "\n",
    "def get_category(attribute):\n",
    "    if attribute == \"Positive\":\n",
    "        return [\"1\", \"0\", \"0\"]\n",
    "    elif attribute == \"Negative\":\n",
    "        return [\"0\", \"1\", \"0\"]\n",
    "    elif attribute == \"Neutral\":\n",
    "        return [\"0\", \"0\", \"1\"]\n",
    "    else:\n",
    "        # raise ValueError('Attribute is wrong')\n",
    "        print attribute\n",
    "        raise ValueError('Attribute is wrong')\n",
    "\n",
    "fpr = open('Sentiment.csv', 'rb')\n",
    "reader = csv.reader(fpr)\n",
    "next(reader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 1369 345\n",
      "592\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "training_labels_y = []\n",
    "training_vects_y = []\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "neu_count = 0\n",
    "negation = 0\n",
    "pos_tweets = []\n",
    "pos_conf = []\n",
    "neg_tweets = []\n",
    "neg_conf = []\n",
    "neu_tweets = []\n",
    "neu_conf = []\n",
    "\n",
    "for row in reader:\n",
    "    if 'Trump' in row[1]: \n",
    "        tweet = row[15]\n",
    "        if len(tweet) < 30:\n",
    "            continue\n",
    "        pattern = re.compile(\n",
    "            r\"(.*(never| no |nothing|nowhere|noone| non|none|nobody| not |\\\n",
    "                |havent|hasnt|hadnt|cant|couldnt|cannot|shouldnt|wasnt|\\\n",
    "                |wont|wouldnt|dont|doesnt|didnt|isnt|arent|\\\n",
    "                |n't|aint))([^.:;!?]*)([.:;!?])(.*)\")\n",
    "        m = re.search(pattern, tweet)\n",
    "        if m:\n",
    "            negation += 1\n",
    "        label = row[5]\n",
    "        confidence = row[6]\n",
    "        if label == 'Positive':\n",
    "            if tweet[0:2] == 'RT':\n",
    "                tweet = tweet[3:]\n",
    "            if tweet not in pos_tweets:\n",
    "                pos_count += 1\n",
    "                pos_tweets.append(tweet)\n",
    "                pos_conf.append(confidence)\n",
    "        if label == 'Negative':\n",
    "            if tweet[0:2] == 'RT':\n",
    "                tweet = tweet[3:]\n",
    "            if tweet not in neg_tweets:\n",
    "                neg_count += 1\n",
    "                neg_tweets.append(tweet)\n",
    "                neg_conf.append(confidence)\n",
    "        if label == 'Neutral':\n",
    "            if tweet[0:2] == 'RT':\n",
    "                tweet = tweet[3:]\n",
    "            if tweet not in neu_tweets:\n",
    "                neu_count += 1\n",
    "                neu_tweets.append(tweet)\n",
    "                neu_conf.append(confidence)\n",
    "\n",
    "        #training_vects_y.append(get_category(label))\n",
    "        #training_labels_y.append(label)\n",
    "#fpr.close()\n",
    "print pos_count, neg_count, neu_count\n",
    "print negation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cPickle.dump(pos_tweets[0:345], open('pos_tweets.pkl','wb'))\n",
    "cPickle.dump(pos_conf[0:345], open('pos_conf.pkl','wb'))\n",
    "cPickle.dump(neg_tweets[0:690], open('neg_tweets.pkl','wb'))\n",
    "cPickle.dump(neg_conf[0:690], open('neg_conf.pkl','wb'))\n",
    "cPickle.dump(neu_tweets[0:345], open('neu_tweets.pkl','wb'))\n",
    "cPickle.dump(neu_conf[0:345], open('neu_conf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n",
      "1380\n",
      "1380\n"
     ]
    }
   ],
   "source": [
    "pos_tweets = pos_tweets[0:345]\n",
    "neg_tweets = neg_tweets[0:690]\n",
    "neu_tweets = neu_tweets[0:345]\n",
    "pos_conf = pos_conf[0:345]\n",
    "neg_conf = neg_conf[0:690]\n",
    "neu_conf = neu_conf[0:345]\n",
    "\n",
    "tweets = pos_tweets + neg_tweets + neu_tweets\n",
    "labels = ['Positive'] * len(pos_tweets) + ['Negative'] * len(neg_tweets) + ['Neutral'] * len(neu_tweets)\n",
    "conf = pos_conf + neg_conf + neu_conf\n",
    "print len(tweets)\n",
    "print len(labels)\n",
    "print len(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Preprocessor import Preprocessor\n",
    "from FeatureExtractor import FeatureExtractor\n",
    "import csv\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor('stopWords.txt')\n",
    "feature_extractor = FeatureExtractor(usingNegation = False, usingStemming = False, usingCorrection = False)\n",
    "feature_space = []\n",
    "features_list = []\n",
    "for tweet in tweets:\n",
    "    processed_tweet = preprocessor.preprocess(tweet)\n",
    "    features = feature_extractor.extract_features_training(processed_tweet)\n",
    "    features_list.append(features)\n",
    "    for feature in features:\n",
    "        if feature not in feature_space:\n",
    "            feature_space.append(feature)\n",
    "print len(feature_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n",
      "1380\n",
      "1288\n",
      "1288\n",
      "1288\n"
     ]
    }
   ],
   "source": [
    "cPickle.dump(feature_space, open('feature_space.pkl','wb'))\n",
    "feature_extractor.get_feature_space('feature_space.pkl')\n",
    "training_vects_x = []\n",
    "for features in features_list:\n",
    "    feature_vect = feature_extractor.build_feature_vector(features)\n",
    "    training_vects_x.append(feature_vect)\n",
    "print len(training_vects_x)\n",
    "\n",
    "\n",
    "pos_vects = []\n",
    "neg_vects = []\n",
    "neu_vects = []\n",
    "X = []\n",
    "pos_conf = []\n",
    "neg_conf = []\n",
    "neu_conf = []\n",
    "\n",
    "print len(conf)\n",
    "for i in xrange(len(training_vects_x)):\n",
    "    if training_vects_x[i] not in X:\n",
    "        X.append(training_vects_x[i])\n",
    "        label = labels[i]\n",
    "        if label == 'Positive':\n",
    "            pos_vects.append(training_vects_x[i])\n",
    "            pos_conf.append(conf[i])\n",
    "        elif label == 'Negative':\n",
    "            neg_vects.append(training_vects_x[i])\n",
    "            neg_conf.append(conf[i])\n",
    "        else:\n",
    "            neu_vects.append(training_vects_x[i])\n",
    "            #print i\n",
    "            neu_conf.append(conf[i])\n",
    "            \n",
    "#X_vects = X_vects_pos + X_vects_neg + X_vects_neu\n",
    "Y = ['Positive'] * len(pos_vects) + ['Negative'] * len(neg_vects) + ['Neutral'] * len(neu_vects)\n",
    "conf = pos_conf + neg_conf + neu_conf\n",
    "print len(Y)\n",
    "print len(X)\n",
    "print len(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "664\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "print len(pos_vects)\n",
    "print len(neg_vects)\n",
    "print len(neu_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cPickle.dump(pos_vects, open('pos_vects.pkl','wb'))\n",
    "cPickle.dump(pos_conf, open('pos_conf.pkl','wb'))\n",
    "cPickle.dump(neg_vects, open('neg_vects.pkl','wb'))\n",
    "cPickle.dump(neg_conf, open('neg_conf.pkl','wb'))\n",
    "cPickle.dump(neu_vects, open('neu_vects.pkl','wb'))\n",
    "cPickle.dump(neu_conf, open('neu_conf.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
